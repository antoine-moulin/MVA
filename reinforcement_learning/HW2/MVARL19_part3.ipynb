{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "MVARL19_part3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rly7ZGiyUKJ6",
        "colab_type": "text"
      },
      "source": [
        "# Exploration in Linear Bandits\n",
        "\n",
        "The objective of this part is to implement and compare the following strategies for linear bandits:\n",
        "\n",
        "[Optimism in the Face of Uncertainty (LinUCB/OFUL)](https://papers.nips.cc/paper/4417-improved-algorithms-for-linear-stochastic-bandits.pdf)\n",
        "\n",
        "[Thompson Sampling](https://projecteuclid.org/euclid.ejs/1513306870)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infCxpaRA0XC",
        "colab_type": "text"
      },
      "source": [
        "## Linear bandit\n",
        "We consider the standard linear bandit setting. At each time $t$, the agent selects an arm $a_t \\in A$ and observes a reward\n",
        "$$\n",
        "r_{a}^t = \\langle \\theta^\\star, \\phi_a^t \\rangle + \\eta_a^t := \\mu_a^t + \\eta_a^t\n",
        "$$\n",
        "where $\\theta^{\\star}¬†\\in \\mathbb{R}^{d}$ is a parameter vector, $\\phi_{a}^t \\in \\mathbb{R}^{d} $ are the features of arm $a$ at time $t$, and $\\eta_{a}^{t}$ is a zero-mean  $\\sigma^2$-subgaussian noise. \n",
        "\n",
        "When the features correspond to the canonical basis, this formulation reduces to multi-armed bandit (MAB) with $d$ arms. In the more general case, the features may depend on a context $x_t$, so that $\\phi_a^t = \\phi(x_t, a)$ denotes the feature vector of a context-action pair $(x_t, a)$ and the resulting setting is the so-called linear contextual bandit.\n",
        "\n",
        "We rely on the following standard assumption on the features and the unknown parameter $\\theta^\\star$.\n",
        "\n",
        "**Assumption.** There exist $B,D \\geq 0$, such that $\\|\\theta^\\star\\|_2 \\leq B$, $\\|\\phi_a^t\\| \\leq D$, and $\\langle \\theta^\\star, \\phi_a^t \\rangle \\in [0,1]$, for all $t$ and $a$.\n",
        "\n",
        "Given a finite horizon $n$, the performance of the agent is measured by its (pseudo)-\\emph{regret}:\n",
        "$$\n",
        "        %R(n) = n \\mu^{\\star} - \\sum_{t=1}^n \\mu_{a_t} = \\sum_{i=1}^K T_i(n) \\Delta_i, \n",
        "        R(n) = \\sum_{t=1}^n \\langle \\theta^\\star, \\phi_{a^\\star}^t \\rangle - \\langle \\theta^\\star, \\phi_{a_t}^t \\rangle ,\n",
        "$$\n",
        "where $a^{\\star}_{t} \\in \\arg\\max_{a} \\langle \\theta^\\star, \\phi_{a}^t \\rangle$ is the optimal action at time $t$.\n",
        "\n",
        "**We consider the simple linear bandit setting:** $\\phi_a^t = \\phi_a, \\; \\forall t$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwPdLAwUWfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf mvarl_hands_on/\n",
        "!git clone https://github.com/rlgammazero/mvarl_hands_on.git\n",
        "!cd mvarl_hands_on/ && git fetch\n",
        "!ls mvarl_hands_on/utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQOcbHbUKJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './mvarl_hands_on/utils')\n",
        "import os\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from coldstart import ColdStartFromDataset\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "import math\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78oy9izEUKKA",
        "colab_type": "text"
      },
      "source": [
        "#### Jester Jokes Dataset (Dense subset of 40 jokes)\n",
        "\n",
        "Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling\n",
        "\n",
        "Download the data at: https://storage.googleapis.com/bandits_datasets/jester_data_40jokes_19181users.npy\n",
        "\n",
        "We performed a matrix factorization of the ratings (after filtering over users and jokes). This provides features for the arms and users, the reward (ie rating) is the dot product between the arm and user features (we make it stochastic by adding Gaussian noise). We consider a cold start problem where the user is randomly selected at the beginning of the repetition and the agent has to learn the best arm to recommend. When an arm is selected by the algorithm, its reward is computed as the dot product between the arm and user features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1YAyl1UKKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bandits_datasets/jester_data_40jokes_19181users.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZsqokZKUKKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = np.load('jester_data_40jokes_19181users.npy')\n",
        "M = M / 10\n",
        "K = 35\n",
        "U, s, Vt = svds(M, k=K)\n",
        "s = np.diag(s)\n",
        "U = np.dot(U,s)\n",
        "print('U: {}'.format(U.shape))\n",
        "print('Vt: {}'.format(Vt.shape))\n",
        "print('#features: {}'.format(Vt.shape[0]))\n",
        "print('#arms: {}'.format(Vt.shape[1]))\n",
        "np.savetxt('U_jester.csv', U, delimiter=',')\n",
        "np.savetxt('Vt_jester.csv', Vt, delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQdkpc-UKKF",
        "colab_type": "text"
      },
      "source": [
        "Create the coldstart model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDXGgf-HUKKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 1235\n",
        "user_subset = np.linspace(0, 400, 10).astype(int).tolist()\n",
        "arm_csvfile = os.path.abspath('Vt_jester.csv')\n",
        "user_csvfile = os.path.abspath('U_jester.csv')\n",
        "noise_std = 0.1\n",
        "\n",
        "config_cs = {\n",
        "    'arm_csvfile': arm_csvfile,\n",
        "    'user_csvfile': user_csvfile,\n",
        "    'random_state': seed,\n",
        "    'user_subset': user_subset,\n",
        "    'noise_std': noise_std\n",
        "}\n",
        "\n",
        "print(\"Current config is:\")\n",
        "pprint(config_cs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPeT4LLUKKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = 0.2\n",
        "random_state = 312\n",
        "model = ColdStartFromDataset(**config_cs)\n",
        "print(\"\\nThe new user arriving to the system is user #\", model.theta_idx)\n",
        "print(\"\\nTheta*: \", model.theta)\n",
        "means = np.dot(model.features, model.theta)\n",
        "print(\"\\nMeans: \", means)\n",
        "theta_bound = np.linalg.norm(model.theta, 2)\n",
        "print(\"\\nTheta bound: \", theta_bound)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KUmWBFlUKKJ",
        "colab_type": "text"
      },
      "source": [
        "**Question 1**: implement LinUCB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G45BzTW_J4Gr",
        "colab_type": "text"
      },
      "source": [
        "### LinUCB / OFUL\n",
        "See the slides!\n",
        "\n",
        "Note that it is not necessary to invert the matrix $A_t$ at each round. Since $A_t$ is obtained from a rank-1 update of $A_{t-1}$, it is possible to use Sherman‚ÄìMorrison formula to build directly $A_t^{-1}$.\n",
        "\n",
        "Suppose $ùê¥$ be a nonsingular $n\\times n$ matrix and $\\mathbf{u}, \\mathbf{v}$ be vectors. Then\n",
        "$$\n",
        "(A+\\mathbf{u}\\mathbf{v}^T)^{-1} = A^{-1} - \\frac{A^{-1}\\mathbf{u}\\mathbf{v}^TA^{-1}}{1+\\mathbf{v}^TA^{-1}\\mathbf{u}}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRC2xoAUKKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OFUL:\n",
        "    def __init__(self, arm_features, reg_factor, delta,\n",
        "                 bound_theta, noise_std):\n",
        "        self.arm_features = arm_features\n",
        "        self.reg_factor = reg_factor\n",
        "        self.delta = delta\n",
        "        self.iteration = 1\n",
        "        self.bound_theta = bound_theta\n",
        "        self.bound_features = np.max(np.sqrt(np.sum(np.abs(arm_features) ** 2, axis=1)))\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "        self.theta = np.zeros(self.n_features)\n",
        "        self.A = self.reg_factor * np.eye(self.n_features)\n",
        "        self.inv_A = np.eye(self.n_features) / self.reg_factor\n",
        "        self.b = np.zeros(self.n_features)\n",
        "\n",
        "    @property\n",
        "    def n_actions(self):\n",
        "        return self.arm_features.shape[0]\n",
        "\n",
        "    @property\n",
        "    def n_features(self):\n",
        "        return self.arm_features.shape[1]\n",
        "    \n",
        "    def compute_estimates(self):\n",
        "        \"\"\"Return the internal estimates\n",
        "        \"\"\"\n",
        "        return self.arm_features @ self.theta\n",
        "\n",
        "    def alpha(self, n_samples):\n",
        "        \"\"\"Return the alpha used to measure uncertainty\n",
        "        \"\"\"\n",
        "        B = self.noise_std\n",
        "        d = self.n_features\n",
        "        t = n_samples # self.iteration\n",
        "        L = self.bound_features\n",
        "        lamb = self.reg_factor\n",
        "        delta = self.delta\n",
        "\n",
        "        # see slide 49\n",
        "        alpha = B * np.sqrt(d * np.log((1 + t * L / lamb) / delta)) + np.sqrt(lamb) * self.bound_theta\n",
        "\n",
        "        return alpha\n",
        "    \n",
        "    def sample_action(self):\n",
        "        \"\"\"Return the action to play based on current estimates\n",
        "        \"\"\"\n",
        "\n",
        "        estimates = self.compute_estimates()\n",
        "        uncertainty = np.zeros(estimates.shape)\n",
        "\n",
        "        for k in range(len(uncertainty)):\n",
        "          uncertainty[k] = self.alpha(self.iteration) * np.sqrt(self.arm_features[k].T @ self.inv_A @ self.arm_features[k])\n",
        "\n",
        "        # see slide 50\n",
        "        combined_value = estimates + uncertainty\n",
        "        action = np.argmax(combined_value)\n",
        "\n",
        "        return action\n",
        "    \n",
        "    def update(self, a_t, r_t):\n",
        "        \"\"\"Update the estimates of the model\n",
        "        \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        a_t: int\n",
        "            The action played at the current episode\n",
        "        r_t: float\n",
        "            The reward associated to action a_t\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        none\n",
        "        \"\"\"\n",
        "\n",
        "        self.iteration += 1\n",
        "\n",
        "        phi_at = self.arm_features[a_t, :]\n",
        "        update = phi_at.reshape(-1, 1) @ phi_at.reshape(1, -1)\n",
        "\n",
        "        self.A += update\n",
        "        self.inv_A -= self.inv_A @ update @ self.inv_A / (1 + phi_at.T @ self.inv_A @ phi_at)\n",
        "        self.b += r_t * phi_at\n",
        "        self.theta = self.inv_A @ self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtwYcKlrK6UP",
        "colab_type": "text"
      },
      "source": [
        "**Question 2:** implement LinearTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xl29-B3MEOC",
        "colab_type": "text"
      },
      "source": [
        "Let $A_t$ be the design matrix, $\\theta_t$ the estimate of $\\theta^\\star$ and $\\beta_t$ the confidence interval built by LinUCB. Then, at every time step t,  LinearTS simply generates\n",
        "a sample $\\tilde{\\theta}_t$ from the distribution $\\mathcal{N}(\\widehat{\\theta}_t, \\omega_t \\alpha_t^2 A_t^{-1})$.\n",
        "\n",
        "LinearTS\n",
        "\n",
        "For $t=1, \\ldots, T$\n",
        "> $\\tilde{\\theta}_t \\sim \\mathcal{N}(\\widehat{\\theta}_t, \\omega_t \\alpha_t^2 A_t^{-1})$\n",
        ">\n",
        "> $a_t \\in \\arg\\max_{a \\in \\mathcal{A}_t}  \\langle \\tilde{\\theta}_t, \\phi_{a} \\rangle$\n",
        ">\n",
        "> observe reward $r_t$\n",
        "\n",
        "TS is requires to draw $\\tilde{\\theta}_t$ from a distribution over-sampling by a factor $\\sqrt{d}$ the ellipsoid constructed by OFUL (i.e., $\\omega_t = d$). This is required to prove that LinearTS is optimistic with a fix probability. This is necessary to prove the frequentist regret of TS. The regret of TS is worse than the one of LinUCB by a factor $\\sqrt{d}$ (i.e., $\\widetilde{O}(d^{3/2}\\sqrt{T})$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTJh0yqgUKKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearTS(OFUL):\n",
        "    def __init__(self, arm_features, reg_factor, delta,\n",
        "                 bound_theta, noise_std, over_sample):\n",
        "        self.over_sample = over_sample\n",
        "        super(LinearTS, self).__init__(arm_features, reg_factor, delta,\n",
        "                 bound_theta, noise_std)\n",
        "        \n",
        "    def compute_estimates(self):\n",
        "        \"\"\"Return the internal estimates\n",
        "        \"\"\"\n",
        "        \n",
        "        mean = self.theta\n",
        "        cov = self.alpha(self.iteration) ** 2 * self.inv_A\n",
        "\n",
        "        if self.over_sample:\n",
        "          cov *= self.n_features\n",
        "\n",
        "        theta_tilde = np.random.multivariate_normal(mean, cov)\n",
        "\n",
        "        return self.arm_features @ theta_tilde\n",
        "\n",
        "    def sample_action(self):\n",
        "        \"\"\"Return the action to play based on current estimates\n",
        "        \"\"\"\n",
        "\n",
        "        return np.argmax(self.compute_estimates())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKERx2_UUKKN",
        "colab_type": "text"
      },
      "source": [
        "**Question 3**: run the algorithms (`LinUCB` and `LinearTS`) and average the performance over multiple users (ie simulations)\n",
        "\n",
        "The regret $R(T) = \\sum_t \\phi_t^\\top (\\theta^\\star - \\theta_t)$\n",
        "\n",
        "The performance is the expected regret over multiple users. You can also test `LinearTS` without the additional $\\sqrt{d}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urKPGY9vXxRn",
        "colab_type": "text"
      },
      "source": [
        "You can use `RandomLinearArms` to test your code before using Jester"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCjrWWuHdpsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from mvarl_hands_on.utils.coldstart import RandomLinearArms\n",
        "\n",
        "def compute_regrets(algorithms, nb_simulations, T, regret_formula='2'):\n",
        "  \"\"\"Compute the regrets\n",
        "  \"\"\"\n",
        "\n",
        "  regrets = {}\n",
        "\n",
        "  for alg_name in algorithms.keys():\n",
        "      if alg_name not in regrets.keys():\n",
        "          regrets[alg_name] = np.zeros((nb_simulations, T))\n",
        "      \n",
        "      for k in range(nb_simulations):\n",
        "          if k % 1 == 0:\n",
        "              print(\"{} simulation {}/{}\".format(alg_name, k+1, nb_simulations))\n",
        "          model = ColdStartFromDataset(**config_cs)\n",
        "  #         model = RandomLinearArms()\n",
        "          alg = algorithms[alg_name](arm_features=model.features, bound_theta=np.linalg.norm(model.theta))\n",
        "\n",
        "          for t in range(T):\n",
        "            a_t = alg.sample_action()\n",
        "            r_t = model.reward(a_t)\n",
        "            alg.update(a_t, r_t)\n",
        "\n",
        "            # compute regret\n",
        "            if regret_formula == '1':  # see formula in the second cell of the notebook\n",
        "              best_action = np.argmax(model.features @ model.theta)\n",
        "              regrets[alg_name][k, t] = model.theta @ (model.features[best_action, :] - model.features[a_t, :])\n",
        "            \n",
        "            elif regret_formula == '2':  # see formula of the question 3\n",
        "              regrets[alg_name][k, t] = model.features[a_t, :] @ (model.theta - alg.theta)\n",
        "  \n",
        "  return regrets\n",
        "\n",
        "def plot_regrets(regrets):\n",
        "  \"\"\"Plot the regrets\n",
        "  \"\"\"\n",
        "  \n",
        "  for alg_name in regrets.keys():\n",
        "      data = np.cumsum(regrets[alg_name], axis=1)\n",
        "      n_rep, T = data.shape\n",
        "      \n",
        "      mean_regret = np.mean(data, axis=0)\n",
        "      std_regret = np.std(data, axis=0) / math.sqrt(n_rep)\n",
        "      t = np.arange(T)\n",
        "      plt.plot(t, mean_regret, label=alg_name)\n",
        "      plt.fill_between(t, mean_regret - 2 * std_regret, mean_regret + 2 * std_regret, alpha=0.15)\n",
        "  plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1tXRlAWmjXp",
        "colab_type": "text"
      },
      "source": [
        "The regret here is defined as: $R(n) = \\sum_{t=1}^n \\langle \\theta^\\star, \\phi_{a^\\star_t}^t \\rangle - \\langle \\theta^\\star, \\phi_{a_t}^t \\rangle ,\n",
        "$ where $a^{\\star}_{t} \\in \\arg\\max_{a} \\langle \\theta^\\star, \\phi_{a}^t \\rangle$ is the optimal action at time $t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1pezF4JUKKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_simulations = 4\n",
        "T = int(4e4)\n",
        "regret_formula = '1'\n",
        "print('Computing (pseudo)-regrets with the first formula of this notebook (second cell).\\n')\n",
        "\n",
        "algorithms = {\n",
        "            'OFUL': lambda arm_features, bound_theta: \n",
        "              OFUL(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std']),\n",
        "             'LinearTS': lambda arm_features, bound_theta:\n",
        "              LinearTS(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std'], over_sample=False)\n",
        "             }\n",
        "regrets1 = compute_regrets(algorithms, nb_simulations, T, regret_formula)\n",
        "\n",
        "algorithms = {\n",
        "            'OFUL': lambda arm_features, bound_theta: \n",
        "              OFUL(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std']),\n",
        "             'LinearTS': lambda arm_features, bound_theta:\n",
        "              LinearTS(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std'], over_sample=True)\n",
        "             }\n",
        "regrets1_oversampling = compute_regrets(algorithms, nb_simulations, T, regret_formula)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('(Pseudo)-regrets without oversampling')\n",
        "plot_regrets(regrets1)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('(Pseudo)-regrets with oversampling')\n",
        "plot_regrets(regrets1_oversampling)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stfai8CYiFx4",
        "colab_type": "text"
      },
      "source": [
        "The regret used here is defined as: $R(T) = \\sum_t \\phi_t^\\top (\\theta^\\star - \\theta_t)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz5uoLmvUKKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_simulations = 4\n",
        "T = int(4e4)\n",
        "regret_formula = '2'\n",
        "print('Computing regrets with the second formula of this notebook (question 3).\\n')\n",
        "\n",
        "algorithms = {\n",
        "            'OFUL': lambda arm_features, bound_theta: \n",
        "              OFUL(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std']),\n",
        "             'LinearTS': lambda arm_features, bound_theta:\n",
        "              LinearTS(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std'], over_sample=False)\n",
        "             }\n",
        "regrets2 = compute_regrets(algorithms, nb_simulations, T, regret_formula)\n",
        "\n",
        "algorithms = {\n",
        "            'OFUL': lambda arm_features, bound_theta: \n",
        "              OFUL(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std']),\n",
        "             'LinearTS': lambda arm_features, bound_theta:\n",
        "              LinearTS(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
        "                 bound_theta=bound_theta, noise_std=config_cs['noise_std'], over_sample=True)\n",
        "             }\n",
        "regrets2_oversampling = compute_regrets(algorithms, nb_simulations, T, regret_formula)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Regrets without oversampling')\n",
        "plot_regrets(regrets2)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Regrets with oversampling')\n",
        "plot_regrets(regrets2_oversampling)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}