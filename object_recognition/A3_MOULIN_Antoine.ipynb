{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Antoine_MOULIN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhoMryEfbrWa",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kRM5UN8W6Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import copy\n",
        "import glob\n",
        "from math import ceil, floor\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image as Image\n",
        "from PIL import ImageOps\n",
        "from skimage.io import imsave\n",
        "\n",
        "!pip install imgaug\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models import resnet50, resnet152\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjzhDmNUbuMb",
        "colab_type": "text"
      },
      "source": [
        "# Bird detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3o0ZEYc7FOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seg_model = maskrcnn_resnet50_fpn(pretrained=True).cuda()\n",
        "seg_model.eval()\n",
        "\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "\n",
        "directory = './bird_dataset'  # images to crop\n",
        "name_dataset = './bird_data'  # folder that is to contain cropped images\n",
        "\n",
        "all_images = glob.glob(directory+'/*/*/*')\n",
        "\n",
        "bird_not_found = 0\n",
        "bird_not_found_list = []\n",
        "\n",
        "threshold = 0.5  # threshold for the detection\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "for k in range(len(all_images)):\n",
        "  \n",
        "  img = Image.open(all_images[k])\n",
        "  img = transform(img).cuda()\n",
        "  pred = seg_model([img])\n",
        "  pred_score = list(pred[0]['scores'].detach().cpu().numpy())\n",
        "\n",
        "  pred_t = [pred_score.index(x) for x in pred_score if x>threshold]\n",
        "  if pred_t != []:\n",
        "    pred_t = pred_t[-1]\n",
        "\n",
        "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].detach().cpu().numpy())]\n",
        "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]\n",
        "    boxes = pred_boxes[:pred_t+1]\n",
        "    pred_cls = pred_class[:pred_t+1]\n",
        "\n",
        "    if 'bird' in pred_cls:\n",
        "      row_min = ceil(boxes[0][0][1])\n",
        "      row_max = floor(boxes[0][1][1])\n",
        "      col_min = ceil(boxes[0][0][0])\n",
        "      col_max = floor(boxes[0][1][0])\n",
        "\n",
        "      new_img = img.cpu().permute(1, 2, 0).numpy()\n",
        "      new_img = new_img[row_min:row_max, col_min:col_max, :]  # crop image\n",
        "\n",
        "      # save new image\n",
        "      new_name = all_images[k].replace(directory, name_dataset)\n",
        "      os.makedirs(os.path.dirname(new_name), exist_ok=True)\n",
        "      imsave(new_name, (new_img*255).astype(np.uint8))\n",
        "\n",
        "    else:  # if no bird has been detected\n",
        "      bird_not_found += 1\n",
        "      bird_not_found_list.append(all_images[k])\n",
        "  \n",
        "  else:  # if nothing has been detected\n",
        "    bird_not_found += 1\n",
        "    bird_not_found_list.append(all_images[k])\n",
        "\n",
        "print('Out of {}, {} have not been found.'.format(len(all_images), bird_not_found))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbEUY65ESe4q",
        "colab_type": "text"
      },
      "source": [
        "# Zero padding to make images square"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8V-ZEK6dECS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_image_square(img):\n",
        "  \"\"\"\n",
        "  Pad a dimension of the image to make it square.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  img: ndarray, shape (width, height, nchannels)\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_img: ndarray, shape (width, width, nchannels) if width > height,\n",
        "                          (height, height, nchannels) if width <= height\n",
        "  \"\"\"\n",
        "\n",
        "  width, height = img.size\n",
        "\n",
        "  if width > height:\n",
        "    delta_h = width - height\n",
        "    padding = (0, delta_h//2, 0, delta_h - (delta_h//2))\n",
        "    new_img = ImageOps.expand(img, padding)\n",
        "\n",
        "  elif width < height:\n",
        "    delta_w = height - width\n",
        "    padding = (delta_w//2, 0, delta_w - (delta_w//2), 0)\n",
        "    new_img = ImageOps.expand(img, padding)\n",
        "\n",
        "  else:\n",
        "    new_img = img\n",
        "\n",
        "  return new_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90LNe61jWMMf",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMIBeFXeSiCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImgAugTransform:\n",
        "  \"\"\"\n",
        "  Class to use augmentation from the library imgaug.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.aug = iaa.Sequential([\n",
        "        iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 1.0))),\n",
        "        iaa.Sometimes(0.25, iaa.CoarseDropout(0.3, size_percent=0.2))\n",
        "        ])\n",
        "      \n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.aug.augment_image(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQhHCNg8VaJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = './bird_data'\n",
        "image_size = 320  # or 224\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    ImgAugTransform(),\n",
        "    transforms.ToPILImage(),\n",
        "    # transforms.Lambda(make_image_square),\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
        "    transforms.ToTensor(),  # to range [0, 1]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(data_dir + '/train_images',\n",
        "                         transform=data_transforms),\n",
        "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(data_dir + '/val_images',\n",
        "                         transform=data_transforms),\n",
        "    batch_size=batch_size, shuffle=False, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYUFJm2NWgjv",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgS7MNJGHd7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nclasses = 20\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  \"\"\"\n",
        "  Class that uses ResNet50 and adds two FC layers and two Dropout layers.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Resnet, self).__init__()\n",
        "    resnet = resnet50(pretrained=True)\n",
        "    modules = list(resnet.children())[:-1]  # remove the last layer\n",
        "    self.resnet = nn.Sequential(*modules)\n",
        "    \n",
        "    self.linear1 = nn.Linear(resnet.fc.in_features, 1024)\n",
        "    self.linear2 = nn.Linear(1024, nclasses)\n",
        "    self.dropout1 = nn.Dropout(p=0.8)\n",
        "    self.dropout2 = nn.Dropout(p=0.5)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.resnet(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout1(x)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    \n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.linear2(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4MNChqcEi8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"\n",
        "  Second class, that can use different networks and not just ResNet50.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, backbone_net):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.backbone_name = backbone_net\n",
        "    if backbone_net == 'resnet50':\n",
        "      backbone = resnet50(pretrained=True)\n",
        "    elif backbone_net == 'resnet152':\n",
        "      backbone = resnet152(pretrained=True)\n",
        "    elif backbone_net == 'resnext101_32x8d':\n",
        "      backbone = resnext101_32x8d(pretrained=True)\n",
        "\n",
        "    modules = list(backbone.children())[:-1]\n",
        "    self.backbone = nn.Sequential(*modules)\n",
        "    \n",
        "    self.linear1 = nn.Linear(backbone.fc.in_features, 1024)\n",
        "    self.linear2 = nn.Linear(1024, nclasses)\n",
        "    self.dropout1 = nn.Dropout(p=0.9)\n",
        "    self.dropout2 = nn.Dropout(p=0.4)\n",
        "\n",
        "    self.classifier = nn.Sequential(self.dropout1, self.linear1, self.dropout2, self.linear2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.backbone(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout1(x)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.linear2(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfMaUZ2GYU7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, use_cuda, model_file, nepochs=50, log_interval=10):\n",
        "  \"\"\"\n",
        "  Function that trains and validates a model.\n",
        "  \"\"\"\n",
        "\n",
        "  since = time.time()\n",
        "  val_acc_history = []\n",
        "\n",
        "  # keep the best model\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(nepochs):\n",
        "    for phase in ['train', 'val']:\n",
        "\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "            \n",
        "      \n",
        "      else:  # if phase == 'val'\n",
        "        model.eval()\n",
        "        validation_loss = 0\n",
        "        correct = 0\n",
        "        for data, target in val_loader:\n",
        "          if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "          output = model(data)\n",
        "          # sum up batch loss\n",
        "          validation_loss += criterion(output, target).data.item()\n",
        "          # get the index of the max log-probability\n",
        "          pred = output.data.max(1, keepdim=True)[1]\n",
        "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "        validation_loss /= len(val_loader.dataset)\n",
        "        validation_accuracy = 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "              validation_loss, correct, len(val_loader.dataset),\n",
        "              validation_accuracy))\n",
        "        \n",
        "        if validation_accuracy > best_acc:\n",
        "          best_acc = validation_accuracy\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('Saved model to ' + model_file + '.\\n')\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  torch.save(model.state_dict(), model_file)\n",
        "  print('Saved model to ' + model_file + '.\\n')\n",
        "  \n",
        "  return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytxMObKQElpL",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTM36iR6BZ1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# initialization\n",
        "if use_cuda:\n",
        "  model = Resnet().cuda()\n",
        "else:\n",
        "  model = Resnet()\n",
        "\n",
        "# parameters\n",
        "model_file = 'experiment/resnet50_{}.pth'.format(image_size)\n",
        "nepochs = 50\n",
        "log_interval = 10\n",
        "\n",
        "# optimization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam([\n",
        "                {'params': list(model.children())[0].parameters(), 'lr': 1e-5},\n",
        "               ], lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
        "\n",
        "# training loop\n",
        "model, val_acc_history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, use_cuda, model_file, nepochs, log_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb5klEA6Wq0L",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOD-QCXke_QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dir = data_dir + '/test_images/mistery_category'\n",
        "outfile = 'experiment/resnet50_320.csv'\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    # transforms.Lambda(make_image_square),\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "output_file = open(outfile, \"w\")\n",
        "output_file.write(\"Id,Category\\n\")\n",
        "for f in tqdm(os.listdir(test_dir)):\n",
        "    if 'jpg' in f:\n",
        "        data = test_transforms(pil_loader(test_dir + '/' + f))\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
        "\n",
        "output_file.close()\n",
        "\n",
        "print(\"Succesfully wrote \" + outfile + ', you can upload this file to the kaggle competition website')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}